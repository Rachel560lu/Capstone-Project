# -*- coding: utf-8 -*-
"""有mask版

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sYiqByPMLDIRMmEr0mCoLgEwH_sHjo2o
"""

import torch
from diffusers import (
    StableDiffusionControlNetInpaintPipeline,
    ControlNetModel,
    UniPCMultistepScheduler,
)
from PIL import Image
import cv2
import numpy as np

# -----------------------------
# 1. 加载 ControlNet 模型
# -----------------------------
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16
)

# -----------------------------
# 2. 加载 Stable Diffusion ControlNet Inpaint Pipeline
# -----------------------------
pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_attention_slicing()
pipe.to("cuda")  # GPU

# -----------------------------
# 3. 读取房间图片 + 自动生成家具 mask
# -----------------------------
from PIL import Image
import numpy as np

def load_and_resize(path, max_side=768):
    img = Image.open(path).convert("RGB")
    w, h = img.size
    scale = max_side / max(w, h)
    if scale < 1.0:
        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)
    return img

# 空房间（没有沙发桌子）
empty_path = "/content/empty_room.png"          
empty_img_pil = load_and_resize(empty_path, max_side=768)

# 已摆好家具的房间 (cured 图)
room_path = "/content/crude_image.png"     
room_img_pil = load_and_resize(room_path, max_side=768)

# 1. 先让两张图同尺寸
empty_img_pil = empty_img_pil.resize(room_img_pil.size, Image.LANCZOS)
width, height = room_img_pil.size

# 2. 强制宽高为 8 的倍数（diffusers 要求）
width = (width // 8) * 8
height = (height // 8) * 8

room_img_pil = room_img_pil.resize((width, height), Image.LANCZOS)
empty_img_pil = empty_img_pil.resize((width, height), Image.LANCZOS)

# 3. 自动生成家具 mask
empty_np = np.array(empty_img_pil).astype(np.int16)
cured_np = np.array(room_img_pil).astype(np.int16)

# 像素差分：家具区域差异大
diff = np.abs(cured_np - empty_np).astype(np.uint8)
diff_gray = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)

# 阈值分割：差异大的认为是家具
_, mask_fg = cv2.threshold(diff_gray, 30, 255, cv2.THRESH_BINARY)  # 30 可调

# 形态学操作，让区域更干净
kernel = np.ones((5, 5), np.uint8)
mask_fg = cv2.morphologyEx(mask_fg, cv2.MORPH_CLOSE, kernel, iterations=2)

# inpaint 的约定：黑色=保留，白色=重绘
mask_inpaint = 255 - mask_fg

# ★ NEW：给 mask 做一点高斯模糊，让边缘变软
mask_inpaint = cv2.GaussianBlur(mask_inpaint, (99, 99), 0)

mask_pil = Image.fromarray(mask_inpaint)
mask_pil = mask_pil.resize((width, height), Image.NEAREST)

# 4. 为 Canny 和 ControlNet 准备输入图像
input_image_rgb = np.array(room_img_pil)                          # RGB
input_image = cv2.cvtColor(input_image_rgb, cv2.COLOR_RGB2BGR)    # BGR

# -----------------------------
# 4. 提取边缘 (ControlNet 需要结构图)
# -----------------------------
canny_image = cv2.Canny(input_image, 100, 200)
canny_image = cv2.cvtColor(canny_image, cv2.COLOR_GRAY2RGB)
canny_pil = Image.fromarray(canny_image)
canny_pil = canny_pil.resize((width, height), Image.NEAREST)


# -----------------------------
# 5. 定义装修风格 prompt
# -----------------------------
prompt = "Modern-style living room interior, no furniture added into the room, use natural lighting from the window"
negative_prompt = " add furniture, add sofa, add table, change room structure, change furniture texture, dim lighting,  low quality"


# -----------------------------
# 6. 生成效果图（带自动家具 mask 的 Inpaint）
# -----------------------------
generator = torch.Generator(device="cuda")

# 调试：全白 mask， 不保护任何区域
white_mask = Image.new("L", (width, height), 255)

output = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,   # 没需要可删
    image=room_img_pil,                # ★ 基础图：有沙发桌子的房间
    control_image=canny_pil,           # ★ ControlNet 的 Canny 结构图
    mask_image=mask_pil,               # ★ 自动生成家具 mask（黑=保留）
    #mask_image=white_mask,              # 全白 mask
    num_inference_steps=25,
    guidance_scale=4.5,
    height=height, width=width,
    num_images_per_prompt=1,
    generator=generator
)


result_image = output.images[0]

# -----------------------------
# 7. 保存效果图
# -----------------------------
result_image.save("furnished_room.png")
canny_pil.save("edge_map.png")
print("装修效果图生成完成！")

from diffusers import UniPCMultistepScheduler

# ★ 优化 scheduler（只需设置一次）
img2img_pipe.scheduler = UniPCMultistepScheduler.from_config(
    img2img_pipe.scheduler.config
)

result2 = img2img_pipe(
    prompt=prompt + ", high detail, sharp focus, 8k, high clarity",   # ★ 强调清晰细节
    negative_prompt=negative_prompt + ", blurry, low detail, soft, smudged",
    image=base,
    strength=0.2,              # ★ 降到 0.05–0.10，只做轻微 harmonize
    guidance_scale=7.0,         # ★ 稍微提高 CFG，让它更听 prompt
    num_inference_steps=30      # ★ 步数拉到 30 左右，细节会回来一些
).images[0]

result2.save("furnished_room_harmonized.png")
