{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8598430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 items from selection.json\n",
      "{'model_id': 'b8b746a5-bf6e-4679-a702-e783140cc4d8', 'super-category': 'Sofa', 'category': 'L-shaped Sofa', 'style': 'Modern', 'price_cny': 4660, 'xLen': 2.087, 'zLen': 0.961, 'footprint_m2': 2.005607}\n",
      "{'model_id': '06791438-cfa8-4e29-95cc-4ff8107e3456', 'super-category': 'Cabinet/Shelf/Desk', 'category': 'Coffee Table', 'style': 'Modern', 'price_cny': 200, 'xLen': 1.08, 'zLen': 0.174, 'footprint_m2': 0.18792}\n",
      "{'model_id': '1a4af735-398a-483b-ad94-68baeb0517bd', 'super-category': 'Cabinet/Shelf/Desk', 'category': 'TV Stand', 'style': 'Modern', 'price_cny': 280, 'xLen': 1.4, 'zLen': 0.482, 'footprint_m2': 0.6748}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# 读取 selection.json\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Desktop/VirtualFurnishing\")\n",
    "selection_path = PROJECT_ROOT / \"furniture_select\" / \"selection.json\"\n",
    "\n",
    "with selection_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    selection = json.load(f)\n",
    "\n",
    "# 简要查看：条目数量与前几个元素\n",
    "print(f\"Loaded {len(selection)} items from selection.json\")\n",
    "for item in selection[:3]:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89177c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.11 (v3.10.11:7d4cc5aa85, Apr  4 2023, 19:05:19) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "Platform: macOS-13.0-arm64-arm-64bit\n",
      "NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "\n",
    "# NumPy 2.x 与部分已编译模块（如 onnxruntime<2，部分扩展）不兼容\n",
    "# 若为 2.x，则给出明确修复提示并中断，避免后续单元格崩溃\n",
    "if not np.__version__.startswith(\"1.\"):\n",
    "    raise RuntimeError(\n",
    "        \"检测到 NumPy>=2（当前版本为 %s）。请将 NumPy 降级到 <2 并确保 onnxruntime/rembg 兼容。\" % np.__version__\n",
    "        + \"\\n修复步骤：\\n\"\n",
    "        + \"1) 在当前虚拟环境中执行：\\n\"\n",
    "        + \"   pip install --upgrade 'numpy<2' 'onnxruntime>=1.16,<2' rembg\\n\"\n",
    "        + \"2) 重启 Jupyter 内核后再运行。\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336d1c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成。成功: 5，失败: 0，输出目录: /Users/apple/Desktop/VirtualFurnishing/outputs/rgba\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 依赖检查：需要 rembg 才能高质量去背景\n",
    "try:\n",
    "    from rembg import remove  # 使用预训练人像/通用抠图模型\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"需要安装 rembg 库以去除背景，请先安装：pip install rembg\"\n",
    "    ) from e\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Desktop/VirtualFurnishing\")\n",
    "images_root = PROJECT_ROOT / \"data\" / \"modern_images\"\n",
    "rgba_out_dir = PROJECT_ROOT / \"outputs\" / \"rgba\"\n",
    "rgba_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 允许的图片扩展名\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"}\n",
    "\n",
    "def find_image_for_model(model_id: str) -> Path | None:\n",
    "    \"\"\"在 images_root 下递归查找包含 model_id 的文件名（不区分大小写）。\"\"\"\n",
    "    lower_id = model_id.lower()\n",
    "    # 先尝试精确匹配文件名（model_id.xxx）\n",
    "    for ext in IMAGE_EXTS:\n",
    "        p = images_root / f\"{model_id}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # 再做一次递归检索，匹配包含 model_id 的文件\n",
    "    for p in images_root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMAGE_EXTS and lower_id in p.stem.lower():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_background_to_rgba(img_path: Path) -> np.ndarray:\n",
    "    \"\"\"使用 rembg 去背景，返回 RGBA 的 numpy 数组。\"\"\"\n",
    "    data = img_path.read_bytes()\n",
    "    out_bytes = remove(data)  # rembg 返回 PNG 字节（通常含 alpha）\n",
    "    arr = np.frombuffer(out_bytes, dtype=np.uint8)\n",
    "    rgba = cv2.imdecode(arr, cv2.IMREAD_UNCHANGED)\n",
    "    if rgba is None:\n",
    "        raise ValueError(f\"解码去背景输出失败: {img_path}\")\n",
    "    # 确保为 4 通道\n",
    "    if rgba.ndim == 3 and rgba.shape[2] == 3:\n",
    "        alpha = np.full((rgba.shape[0], rgba.shape[1], 1), 255, dtype=rgba.dtype)\n",
    "        rgba = np.concatenate([rgba, alpha], axis=2)\n",
    "    return rgba\n",
    "\n",
    "\n",
    "failed = []\n",
    "processed = 0\n",
    "\n",
    "for item in selection:\n",
    "    model_id = item.get(\"model_id\")\n",
    "    if not model_id:\n",
    "        continue\n",
    "    img_path = find_image_for_model(model_id)\n",
    "    if img_path is None:\n",
    "        print(f\"[缺失] 未找到图片: {model_id}\")\n",
    "        failed.append((model_id, \"not_found\"))\n",
    "        continue\n",
    "    try:\n",
    "        rgba = remove_background_to_rgba(img_path)\n",
    "        out_path = rgba_out_dir / f\"{model_id}.png\"\n",
    "        # cv2.imwrite 需要 BGR(A)，rembg 输出已是 BGRA；直接保存\n",
    "        ok = cv2.imwrite(str(out_path), rgba)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"cv2.imwrite 失败\")\n",
    "        processed += 1\n",
    "        if processed % 10 == 0:\n",
    "            print(f\"已处理 {processed} 张...\")\n",
    "    except Exception as e:\n",
    "        print(f\"[失败] {model_id}: {e}\")\n",
    "        failed.append((model_id, str(e)))\n",
    "\n",
    "print(f\"完成。成功: {processed}，失败: {len(failed)}，输出目录: {rgba_out_dir}\")\n",
    "if failed:\n",
    "    print(\"部分失败列举前 5 条:\")\n",
    "    for x in failed[:5]:\n",
    "        print(\"  \", x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2dc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成对比图 5 张，输出目录: /Users/apple/Desktop/VirtualFurnishing/outputs/compare\n",
      "拼图已保存: /Users/apple/Desktop/VirtualFurnishing/outputs/selection_collage.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Desktop/VirtualFurnishing\")\n",
    "images_root = PROJECT_ROOT / \"data\" / \"modern_images\"\n",
    "rgba_out_dir = PROJECT_ROOT / \"outputs\" / \"rgba\"\n",
    "compare_out_dir = PROJECT_ROOT / \"outputs\" / \"compare\"\n",
    "compare_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 尝试加载系统字体（若失败回退到默认）\n",
    "try:\n",
    "    font = ImageFont.truetype(\"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\", 18)\n",
    "except Exception:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "\n",
    "def to_pil(image_bgr_or_bgra: np.ndarray) -> Image.Image:\n",
    "    if image_bgr_or_bgra.ndim == 2:\n",
    "        return Image.fromarray(image_bgr_or_bgra)\n",
    "    if image_bgr_or_bgra.shape[2] == 3:\n",
    "        return Image.fromarray(cv2.cvtColor(image_bgr_or_bgra, cv2.COLOR_BGR2RGB))\n",
    "    if image_bgr_or_bgra.shape[2] == 4:\n",
    "        return Image.fromarray(cv2.cvtColor(image_bgr_or_bgra, cv2.COLOR_BGRA2RGBA))\n",
    "    raise ValueError(\"Unsupported image shape\")\n",
    "\n",
    "\n",
    "def render_checkerboard(size: Tuple[int, int], cell: int = 16) -> Image.Image:\n",
    "    w, h = size\n",
    "    bg = Image.new(\"RGB\", size, (220, 220, 220))\n",
    "    draw = ImageDraw.Draw(bg)\n",
    "    for y in range(0, h, cell):\n",
    "        for x in range(0, w, cell):\n",
    "            if (x // cell + y // cell) % 2 == 0:\n",
    "                draw.rectangle([x, y, x + cell, y + cell], fill=(245, 245, 245))\n",
    "    return bg\n",
    "\n",
    "\n",
    "def alpha_composite_on_checker(rgba_arr: np.ndarray, max_side: int = 512) -> Image.Image:\n",
    "    rgba = to_pil(rgba_arr)\n",
    "    # 等比缩放到不超过 max_side\n",
    "    ratio = min(max_side / rgba.width, max_side / rgba.height, 1.0)\n",
    "    new_size = (max(1, int(rgba.width * ratio)), max(1, int(rgba.height * ratio)))\n",
    "    rgba = rgba.resize(new_size, Image.LANCZOS)\n",
    "    bg = render_checkerboard(rgba.size)\n",
    "    bg = bg.convert(\"RGBA\")\n",
    "    bg.alpha_composite(rgba, (0, 0))\n",
    "    return bg.convert(\"RGB\")\n",
    "\n",
    "\n",
    "def resize_max_side(img: Image.Image, max_side: int = 512) -> Image.Image:\n",
    "    ratio = min(max_side / img.width, max_side / img.height, 1.0)\n",
    "    return img.resize((max(1, int(img.width * ratio)), max(1, int(img.height * ratio))), Image.LANCZOS)\n",
    "\n",
    "\n",
    "def make_side_by_side(original_path: Path, rgba_path: Path, title: str, max_side: int = 512) -> Image.Image:\n",
    "    # 读原图\n",
    "    orig_bgr = cv2.imread(str(original_path), cv2.IMREAD_COLOR)\n",
    "    if orig_bgr is None:\n",
    "        raise FileNotFoundError(f\"原图无法读取: {original_path}\")\n",
    "    # 读抠图结果\n",
    "    cut = cv2.imread(str(rgba_path), cv2.IMREAD_UNCHANGED)\n",
    "    if cut is None:\n",
    "        raise FileNotFoundError(f\"抠图无法读取: {rgba_path}\")\n",
    "\n",
    "    orig_pil = resize_max_side(to_pil(orig_bgr), max_side)\n",
    "    cut_vis = alpha_composite_on_checker(cut, max_side)\n",
    "\n",
    "    padding = 16\n",
    "    title_h = 32\n",
    "    canvas_w = orig_pil.width + cut_vis.width + padding * 3\n",
    "    canvas_h = max(orig_pil.height, cut_vis.height) + padding * 2 + title_h\n",
    "    canvas = Image.new(\"RGB\", (canvas_w, canvas_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "    # 标题\n",
    "    draw.text((padding, padding), title, font=font, fill=(0, 0, 0))\n",
    "\n",
    "    # 图片位置\n",
    "    y0 = padding + title_h\n",
    "    x1 = padding\n",
    "    x2 = x1 + orig_pil.width + padding\n",
    "\n",
    "    canvas.paste(orig_pil, (x1, y0))\n",
    "    canvas.paste(cut_vis, (x2, y0))\n",
    "\n",
    "    # 标注\n",
    "    draw.text((x1, y0 - 24), \"Original\", font=font, fill=(80, 80, 80))\n",
    "    draw.text((x2, y0 - 24), \"Cutout\", font=font, fill=(80, 80, 80))\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def build_all_comparisons(items: List[dict], limit: int | None = None) -> list[Path]:\n",
    "    out_paths: list[Path] = []\n",
    "    count = 0\n",
    "    for item in items:\n",
    "        if limit is not None and count >= limit:\n",
    "            break\n",
    "        model_id = item.get(\"model_id\")\n",
    "        if not model_id:\n",
    "            continue\n",
    "        # 原图路径复用查找函数（已在上文定义）\n",
    "        orig = find_image_for_model(model_id)\n",
    "        cut = rgba_out_dir / f\"{model_id}.png\"\n",
    "        if orig is None or not cut.exists():\n",
    "            # 跳过缺失\n",
    "            continue\n",
    "        try:\n",
    "            title = f\"{model_id} | {item.get('category','')} | {item.get('style','')}\"\n",
    "            canvas = make_side_by_side(orig, cut, title)\n",
    "            save_path = compare_out_dir / f\"{model_id}_compare.png\"\n",
    "            canvas.save(save_path)\n",
    "            out_paths.append(save_path)\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"对比生成失败 {model_id}: {e}\")\n",
    "    print(f\"已生成对比图 {len(out_paths)} 张，输出目录: {compare_out_dir}\")\n",
    "    return out_paths\n",
    "\n",
    "\n",
    "def grid_collage(image_paths: List[Path], cols: int = 2, cell_w: int = 640, cell_h: int = 480, gap: int = 16) -> Image.Image:\n",
    "    if not image_paths:\n",
    "        raise ValueError(\"无可用对比图构建拼图\")\n",
    "    rows = math.ceil(len(image_paths) / cols)\n",
    "    W = cols * cell_w + (cols + 1) * gap\n",
    "    H = rows * cell_h + (rows + 1) * gap\n",
    "    board = Image.new(\"RGB\", (W, H), (255, 255, 255))\n",
    "    for idx, p in enumerate(image_paths):\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        img = resize_max_side(img, min(cell_w, cell_h))\n",
    "        r = idx // cols\n",
    "        c = idx % cols\n",
    "        x = gap + c * (cell_w + gap) + (cell_w - img.width) // 2\n",
    "        y = gap + r * (cell_h + gap) + (cell_h - img.height) // 2\n",
    "        board.paste(img, (x, y))\n",
    "    return board\n",
    "\n",
    "# 运行：为所有 selection 生成对比 + 拼图\n",
    "compare_list = build_all_comparisons(selection)\n",
    "if compare_list:\n",
    "    collage = grid_collage(compare_list, cols=2, cell_w=720, cell_h=540, gap=24)\n",
    "    collage_path = PROJECT_ROOT / \"outputs\" / \"selection_collage.png\"\n",
    "    collage.save(collage_path)\n",
    "    print(f\"拼图已保存: {collage_path}\")\n",
    "else:\n",
    "    print(\"没有生成任何对比图（可能原图或抠图缺失）\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9db0578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将作为前景的 ADE20K 类别数: 19 | device: cpu\n",
      "SegFormer 已处理 5 张...\n",
      "SegFormer 完成。成功: 5，失败: 0，输出目录: /Users/apple/Desktop/VirtualFurnishing/outputs/rgba\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Set\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 使用 HuggingFace SegFormer（ADE20K）进行语义分割，生成家具前景掩码\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Desktop/VirtualFurnishing\")\n",
    "images_root = PROJECT_ROOT / \"data\" / \"modern_images\"\n",
    "rgba_out_dir = PROJECT_ROOT / \"outputs\" / \"rgba\"\n",
    "rgba_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 加载模型与处理器（建议首次运行联网下载权重）\n",
    "SEGFORMER_MODEL_ID = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
    "processor = SegformerImageProcessor.from_pretrained(SEGFORMER_MODEL_ID)\n",
    "segformer = AutoModelForSemanticSegmentation.from_pretrained(SEGFORMER_MODEL_ID)\n",
    "segformer.eval()\n",
    "\n",
    "# 设备选择（优先 CUDA，其次 Apple MPS，最后 CPU）\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "segformer.to(device)\n",
    "\n",
    "# 选择与家具相关的 ADE20K 类别（名称子串匹配）\n",
    "FURNITURE_KEYWORDS = {\n",
    "    \"sofa\", \"couch\", \"chair\", \"armchair\", \"stool\", \"bench\",\n",
    "    \"table\", \"desk\", \"coffee table\", \"cabinet\", \"shelf\", \"bookcase\",\n",
    "    \"wardrobe\", \"bed\", \"lamp\", \"chandelier\", \"television\", \"tv\", \"stand\"\n",
    "}\n",
    "\n",
    "# 从模型配置获取 id->label 映射\n",
    "id2label = segformer.config.id2label\n",
    "label2id = {v.lower(): k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "def build_furniture_ids_from_keywords() -> Set[int]:\n",
    "    include_ids: Set[int] = set()\n",
    "    for cid, name in id2label.items():\n",
    "        low = name.lower()\n",
    "        for kw in FURNITURE_KEYWORDS:\n",
    "            if kw in low:\n",
    "                include_ids.add(int(cid))\n",
    "                break\n",
    "    return include_ids\n",
    "\n",
    "INCLUDE_IDS = build_furniture_ids_from_keywords()\n",
    "print(f\"将作为前景的 ADE20K 类别数: {len(INCLUDE_IDS)} | device: {device}\")\n",
    "\n",
    "\n",
    "def segformer_mask_for_image(img_bgr: np.ndarray, include_ids: Set[int]) -> np.ndarray:\n",
    "    # 输入为 BGR；转 RGB 给模型\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    inputs = processor(images=img_rgb, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = segformer(**inputs)\n",
    "        logits = outputs.logits  # [1, num_labels, H/4, W/4]\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=img_rgb.shape[:2],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        pred = upsampled_logits.argmax(dim=1)[0].detach().cpu().numpy().astype(np.int32)\n",
    "    mask = np.isin(pred, list(include_ids)).astype(np.uint8)  # 0/1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def cutout_with_mask(img_bgr: np.ndarray, mask01: np.ndarray) -> np.ndarray:\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    if mask01.shape != (h, w):\n",
    "        mask01 = cv2.resize(mask01, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    alpha = (mask01 * 255).astype(np.uint8)\n",
    "    rgba = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2BGRA)\n",
    "    rgba[:, :, 3] = alpha\n",
    "    return rgba\n",
    "\n",
    "\n",
    "# 对 selection 中的每个条目，使用 SegFormer 生成 RGBA\n",
    "failed = []\n",
    "processed = 0\n",
    "\n",
    "for item in selection:\n",
    "    model_id = item.get(\"model_id\")\n",
    "    if not model_id:\n",
    "        continue\n",
    "    img_path = find_image_for_model(model_id)\n",
    "    if img_path is None:\n",
    "        print(f\"[缺失] 未找到图片: {model_id}\")\n",
    "        failed.append((model_id, \"not_found\"))\n",
    "        continue\n",
    "    img_bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        print(f\"[失败] 原图读取失败: {model_id}\")\n",
    "        failed.append((model_id, \"read_fail\"))\n",
    "        continue\n",
    "    try:\n",
    "        rgba = cutout_with_mask(img_bgr, segformer_mask_for_image(img_bgr, INCLUDE_IDS))\n",
    "        out_path = rgba_out_dir / f\"{model_id}.png\"\n",
    "        ok = cv2.imwrite(str(out_path), rgba)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"cv2.imwrite 失败\")\n",
    "        processed += 1\n",
    "        if processed % 5 == 0:\n",
    "            print(f\"SegFormer 已处理 {processed} 张...\")\n",
    "    except Exception as e:\n",
    "        print(f\"[失败] SegFormer {model_id}: {e}\")\n",
    "        failed.append((model_id, str(e)))\n",
    "\n",
    "print(f\"SegFormer 完成。成功: {processed}，失败: {len(failed)}，输出目录: {rgba_out_dir}\")\n",
    "if failed:\n",
    "    print(\"部分失败列举前 5 条:\")\n",
    "    for x in failed[:5]:\n",
    "        print(\"  \", x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8ae874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "改进版 SegFormer 已处理 5 张...\n",
      "改进版完成。成功: 5，失败: 0 -> 输出: /Users/apple/Desktop/VirtualFurnishing/outputs/rgba\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Set\n",
    "import cv2, numpy as np, torch\n",
    "\n",
    "# 复用已有对象\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Desktop/VirtualFurnishing\")\n",
    "rgba_out_dir = PROJECT_ROOT / \"outputs\" / \"rgba\"\n",
    "rgba_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 若缺少则补：INCLUDE_IDS / processor / segformer / device\n",
    "try:\n",
    "    INCLUDE_IDS\n",
    "    processor\n",
    "    segformer\n",
    "    device\n",
    "except NameError:\n",
    "    from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "    SEGFORMER_MODEL_ID = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
    "    processor = SegformerImageProcessor.from_pretrained(SEGFORMER_MODEL_ID)\n",
    "    segformer = AutoModelForSemanticSegmentation.from_pretrained(SEGFORMER_MODEL_ID).eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() else \"cpu\"))\n",
    "    segformer.to(device)\n",
    "    id2label = segformer.config.id2label\n",
    "    FURNITURE_KEYWORDS = {\"sofa\",\"couch\",\"chair\",\"armchair\",\"stool\",\"bench\",\"table\",\"desk\",\"coffee table\",\"cabinet\",\"shelf\",\"bookcase\",\"wardrobe\",\"bed\",\"lamp\",\"chandelier\",\"television\",\"tv\",\"stand\"}\n",
    "    def build_ids()->Set[int]:\n",
    "        s=set()\n",
    "        for cid,name in id2label.items():\n",
    "            low=name.lower()\n",
    "            if any(k in low for k in FURNITURE_KEYWORDS): s.add(int(cid))\n",
    "        return s\n",
    "    INCLUDE_IDS = build_ids()\n",
    "\n",
    "def postprocess_mask(mask01: np.ndarray, min_area_ratio=0.003, close_ks=9, open_ks=5, keep_k=1):\n",
    "    h, w = mask01.shape\n",
    "    if close_ks>0: mask01 = cv2.morphologyEx(mask01, cv2.MORPH_CLOSE, np.ones((close_ks,close_ks), np.uint8))\n",
    "    if open_ks>0:  mask01 = cv2.morphologyEx(mask01, cv2.MORPH_OPEN,  np.ones((open_ks,open_ks), np.uint8))\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask01.astype(np.uint8), connectivity=8)\n",
    "    if num>1:\n",
    "        areas = sorted([(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1,num)], key=lambda x:x[1], reverse=True)\n",
    "        keep = {i for i,a in areas[:keep_k] if a >= min_area_ratio*h*w}\n",
    "        new = np.zeros_like(mask01, np.uint8)\n",
    "        for i in keep: new[labels==i]=1\n",
    "        mask01 = new\n",
    "    return mask01\n",
    "\n",
    "def feather_alpha(binary_mask: np.ndarray, feather=5):\n",
    "    b = (binary_mask>0).astype(np.uint8)\n",
    "    dist_in  = cv2.distanceTransform(b,  cv2.DIST_L2, 3)\n",
    "    dist_out = cv2.distanceTransform(1-b, cv2.DIST_L2, 3)\n",
    "    alpha = dist_in / (dist_in + dist_out + 1e-6)\n",
    "    if feather>0: alpha = cv2.GaussianBlur(alpha, (feather*2+1, feather*2+1), 0)\n",
    "    return np.clip(alpha, 0, 1)\n",
    "\n",
    "def segformer_alpha(img_bgr: np.ndarray, include_ids: Set[int]) -> np.ndarray:\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    inputs = {k: v.to(device) for k,v in processor(images=img_rgb, return_tensors=\"pt\").items()}\n",
    "    with torch.no_grad():\n",
    "        logits = segformer(**inputs).logits\n",
    "        up = torch.nn.functional.interpolate(logits, size=img_rgb.shape[:2], mode=\"bilinear\", align_corners=False)\n",
    "        probs = torch.softmax(up, dim=1)[0]             # [C,H,W]\n",
    "        fg = (probs[list(include_ids)].amax(dim=0) if len(include_ids)>0 else probs.amax(dim=0)).cpu().numpy().astype(np.float32)\n",
    "    binary = (fg >= 0.5).astype(np.uint8)\n",
    "    binary = postprocess_mask(binary, min_area_ratio=0.003, close_ks=9, open_ks=5, keep_k=1)\n",
    "    alpha = feather_alpha(binary, feather=5)\n",
    "    return np.maximum(alpha, fg)\n",
    "\n",
    "def cutout_with_alpha(img_bgr: np.ndarray, alpha01: np.ndarray) -> np.ndarray:\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    if alpha01.shape!=(h,w): alpha01 = cv2.resize(alpha01, (w,h), interpolation=cv2.INTER_LINEAR)\n",
    "    rgba = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2BGRA)\n",
    "    rgba[:,:,3] = (alpha01*255).astype(np.uint8)\n",
    "    return rgba\n",
    "\n",
    "failed, processed = [], 0\n",
    "for item in selection:\n",
    "    mid = item.get(\"model_id\"); \n",
    "    if not mid: continue\n",
    "    p = find_image_for_model(mid)\n",
    "    if p is None: failed.append((mid,\"not_found\")); continue\n",
    "    img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if img is None: failed.append((mid,\"read_fail\")); continue\n",
    "    try:\n",
    "        alpha = segformer_alpha(img, INCLUDE_IDS)\n",
    "        rgba = cutout_with_alpha(img, alpha)\n",
    "        cv2.imwrite(str(rgba_out_dir / f\"{mid}.png\"), rgba)\n",
    "        processed += 1\n",
    "        if processed % 5 == 0: print(f\"改进版 SegFormer 已处理 {processed} 张...\")\n",
    "    except Exception as e:\n",
    "        failed.append((mid, str(e)))\n",
    "print(f\"改进版完成。成功: {processed}，失败: {len(failed)} -> 输出: {rgba_out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c43b76",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
